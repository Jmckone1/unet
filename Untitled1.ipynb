{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from Code_UNet.Unet_modules.RANO_dataloader_2 import BraTs_Dataset\n",
    "from Code_UNet.Unet_modules.dataloader_test import Test_Dataset\n",
    "import Code_UNet.Net.Unet_Rano_components as net\n",
    "import csv\n",
    "from os import walk\n",
    "import nibabel as nib\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.metrics import jaccard_score\n",
    "from matplotlib.path import Path\n",
    "\n",
    "def MSELossorthog(output, target):\n",
    "    \n",
    "    #weighting values for orthogonality and area constraints\n",
    "    orth_weight = 4\n",
    "    area_weight = 4\n",
    "    \n",
    "    # convert prediction and truth to np data\n",
    "    output_val = output.data.cpu().numpy()\n",
    "    \n",
    "    #target_val = target.data.Tensor.cpu().numpy()\n",
    "    target_val = target.cpu().data.numpy()\n",
    "    \n",
    "    batch_size = output_val.shape[0]\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        # calculate the lengths of each of the lines (prediction = l1, l2) (truth = l3,l4)\n",
    "        l1 = np.sqrt(np.square(output_val[i][1]-output_val[i][3]) + np.square(output_val[i][0]-output_val[i][2]))\n",
    "        l2 = np.sqrt(np.square(output_val[i][5]-output_val[i][7]) + np.square(output_val[i][4]-output_val[i][6]))\n",
    "        l3 = np.sqrt(np.square(target_val[i][1]-target_val[i][3]) + np.square(target_val[i][0]-target_val[i][2]))\n",
    "        l4 = np.sqrt(np.square(target_val[i][5]-target_val[i][7]) + np.square(target_val[i][4]-target_val[i][6]))\n",
    "\n",
    "        # calculate the slope of each of the lines\n",
    "        m1 = (abs(output_val[i][1]/l1-output_val[i][3]/l1))/(abs(output_val[i][0]/l1-output_val[i][2]/l1)+0.1)\n",
    "        m2 = (abs(output_val[i][5]/l2-output_val[i][7]/l2))/(abs(output_val[i][4]/l2-output_val[i][6]/l2)+0.1)\n",
    "\n",
    "        # calculate the orthogonality/ perpendicularity with 0 being perpendicular, 100 being parallel\n",
    "        orthog = abs(np.dot(m1,m2))\n",
    "\n",
    "        # calculate the area of the detected object to try and balance out the lengths of the lines (one of  which always appears to be significantly shorter than that of the other which is often more correct\n",
    "        output_area = l1*l2 \n",
    "        target_area = l3*l4\n",
    "\n",
    "        output_area_norm = output_area / (output_area+target_area)\n",
    "        target_area_norm = target_area / (output_area+target_area)\n",
    "\n",
    "        area_penalty = abs(output_area_norm - target_area_norm) * 100\n",
    "\n",
    "        loss = loss + torch.mean((output[i] - target[i])**2) + (orthog * orth_weight) + (area_penalty * area_weight)\n",
    "\n",
    "    return loss / batch_size\n",
    "\n",
    "# image interpolation multiplier\n",
    "size = 1\n",
    "\n",
    "# BCE with Logits loss, may change to soft dice\n",
    "criterion = MSELossorthog\n",
    "\n",
    "n_epochs = 6\n",
    "input_dim = 4\n",
    "label_dim = 8\n",
    "hidden_dim = 32\n",
    "\n",
    "display_step = True\n",
    "batch_size = 16\n",
    "lr = 0.0002\n",
    "initial_shape = int(240 * size)\n",
    "target_shape = int(8)\n",
    "device = 'cuda'\n",
    "\n",
    "unet = net.UNet(input_dim, label_dim, hidden_dim).to(device)\n",
    "unet_opt = torch.optim.Adam(unet.parameters(), lr=lr, weight_decay=1e-8)\n",
    "\n",
    "checkpoint = torch.load(\"Checkpoints_RANO/Unet_8_2_data/checkpoint_49.pth\")\n",
    "\n",
    "unet.load_state_dict(checkpoint['state_dict'])\n",
    "unet_opt.load_state_dict(checkpoint['optimizer'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unet)\n",
    "#print(unet.Linear1)\n",
    "#print(unet.children())\n",
    "\n",
    "unet2 = nn.Sequential(*list(unet.children())[:-1])\n",
    "print(unet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "import Code_UNet.Net.Unet_Rano_components as net\n",
    "\n",
    "def MSELossorthog(output, target):\n",
    "    \n",
    "    #weighting values for orthogonality and area constraints\n",
    "    orth_weight = 4\n",
    "    area_weight = 4\n",
    "    \n",
    "    # convert prediction and truth to np data\n",
    "    output_val = output.data.cpu().numpy()\n",
    "    \n",
    "    #target_val = target.data.Tensor.cpu().numpy()\n",
    "    target_val = target.cpu().data.numpy()\n",
    "    \n",
    "    batch_size = output_val.shape[0]\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        # calculate the lengths of each of the lines (prediction = l1, l2) (truth = l3,l4)\n",
    "        l1 = np.sqrt(np.square(output_val[i][1]-output_val[i][3]) + np.square(output_val[i][0]-output_val[i][2]))\n",
    "        l2 = np.sqrt(np.square(output_val[i][5]-output_val[i][7]) + np.square(output_val[i][4]-output_val[i][6]))\n",
    "        l3 = np.sqrt(np.square(target_val[i][1]-target_val[i][3]) + np.square(target_val[i][0]-target_val[i][2]))\n",
    "        l4 = np.sqrt(np.square(target_val[i][5]-target_val[i][7]) + np.square(target_val[i][4]-target_val[i][6]))\n",
    "\n",
    "        # calculate the slope of each of the lines\n",
    "        m1 = (abs(output_val[i][1]/l1-output_val[i][3]/l1))/(abs(output_val[i][0]/l1-output_val[i][2]/l1)+0.1)\n",
    "        m2 = (abs(output_val[i][5]/l2-output_val[i][7]/l2))/(abs(output_val[i][4]/l2-output_val[i][6]/l2)+0.1)\n",
    "\n",
    "        # calculate the orthogonality/ perpendicularity with 0 being perpendicular, 100 being parallel\n",
    "        orthog = abs(np.dot(m1,m2))\n",
    "\n",
    "        # calculate the area of the detected object to try and balance out the lengths of the lines (one of  which always appears to be significantly shorter than that of the other which is often more correct\n",
    "        output_area = l1*l2 \n",
    "        target_area = l3*l4\n",
    "\n",
    "        output_area_norm = output_area / (output_area+target_area)\n",
    "        target_area_norm = target_area / (output_area+target_area)\n",
    "\n",
    "        area_penalty = abs(output_area_norm - target_area_norm) * 100\n",
    "\n",
    "        loss = loss + torch.mean((output[i] - target[i])**2) + (orthog * orth_weight) + (area_penalty * area_weight)\n",
    "\n",
    "    return loss / batch_size\n",
    "\n",
    "# image interpolation multiplier\n",
    "size = 1\n",
    "\n",
    "# BCE with Logits loss, may change to soft dice\n",
    "criterion = MSELossorthog\n",
    "\n",
    "n_epochs = 6\n",
    "input_dim = 4\n",
    "label_dim = 8\n",
    "hidden_dim = 32\n",
    "\n",
    "display_step = True\n",
    "batch_size = 16\n",
    "lr = 0.0002\n",
    "initial_shape = int(240 * size)\n",
    "target_shape = int(8)\n",
    "device = 'cuda'\n",
    "\n",
    "#expanding path of the model\n",
    "class Expand(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(Expand, self).__init__()\n",
    "        \n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.conv1 = nn.Conv2d(input_channels, input_channels//2, kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(input_channels, input_channels//2, kernel_size=3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(input_channels//2, input_channels//2, kernel_size=3,padding=1)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, skip_con_x):\n",
    "        x = self.upsample(x)\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet\n",
    "        # /commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        diffY = skip_con_x.size()[2] - x.size()[2]\n",
    "        diffX = skip_con_x.size()[3] - x.size()[3]\n",
    "        x = F.pad(x, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
    "\n",
    "        x = torch.cat([skip_con_x, x], dim=1)\n",
    "        x = self.conv2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class FeatureMap(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(FeatureMap, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(input_channels, output_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class UNet2(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, hidden_channels=32):\n",
    "        super(UNet2, self).__init__()\n",
    "        \n",
    "        self.unet = net.UNet(input_channels, output_channels, hidden_channels).to(device)\n",
    "        checkpoint = torch.load(\"Checkpoints_RANO/Unet_8_2_data/checkpoint_49.pth\")\n",
    "        self.unet.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "        self.expand0 = Expand(hidden_channels * 32)\n",
    "        self.expand1 = Expand(hidden_channels * 16)\n",
    "        self.expand2 = Expand(hidden_channels * 8)\n",
    "        self.expand3 = Expand(hidden_channels * 4)\n",
    "        self.expand4 = Expand(hidden_channels * 2)\n",
    "        \n",
    "        self.downfeature = FeatureMap(hidden_channels, output_channels)\n",
    "        \n",
    "    def forward(self):\n",
    "        \n",
    "        expand_1 = self.expand0(unet.contract5)\n",
    "        expand_2 = self.expand1(unet.contract4)\n",
    "        expand_3 = self.expand2(unet.contract3)\n",
    "        expand_4 = self.expand3(unet.contract2)\n",
    "        expand_5 = self.expand4(unet.contract1)\n",
    "        \n",
    "        data_out = self.downfeature(expand_5)\n",
    "        \n",
    "        return data_out\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, hidden_channels=32):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        unet = net.UNet(input_channels, output_channels, hidden_channels).to(device)\n",
    "        checkpoint = torch.load(\"Checkpoints_RANO/Unet_8_2_data/checkpoint_49.pth\")\n",
    "        unet.load_state_dict(checkpoint['state_dict'])\n",
    "        \n",
    "        self.model = unet\n",
    "        \n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "class Merge(nn.Module):\n",
    "    def __init__(self, contract, expand):\n",
    "        super(Merge, self).__init__()\n",
    "        self.contract = contract\n",
    "        self.expand = expand\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.contract(input_dim, label_dim, hidden_dim)\n",
    "        x2 = self.expand(x1)\n",
    "        return x2\n",
    "    \n",
    "unet  = Merge(UNet,UNet2)\n",
    "\n",
    "unet1 = unet(1).to(device)\n",
    "print(unet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full_UNet(\n",
      "  (contract): UNet_contracting(\n",
      "    (upfeature): FeatureMap(\n",
      "      (conv): Conv2d(4, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (contract1): Contract(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): ReLU()\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (contract2): Contract(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): ReLU()\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (contract3): Contract(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): ReLU()\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (contract4): Contract(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): ReLU()\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (contract5): Contract(\n",
      "      (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): ReLU()\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (expand): UNet_expanding(\n",
      "    (expand0): Expand(\n",
      "      (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(2, 2), stride=(1, 1))\n",
      "      (conv2): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (expand1): Expand(\n",
      "      (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "      (conv2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (expand2): Expand(\n",
      "      (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(2, 2), stride=(1, 1))\n",
      "      (conv2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (expand3): Expand(\n",
      "      (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "      (conv2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (expand4): Expand(\n",
      "      (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (conv1): Conv2d(64, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "      (conv2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (downfeature): FeatureMap(\n",
      "      (conv): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "import Code_UNet.Net.Unet_Rano_components as net\n",
    "\n",
    "# contracting path of the model\n",
    "class Contract(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(Contract, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(input_channels, input_channels*2, kernel_size=3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(input_channels*2, input_channels*2, kernel_size=3,padding=1)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class FeatureMap(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(FeatureMap, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(input_channels, output_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class UNet_contracting(nn.Module):\n",
    "\n",
    "    def __init__(self, input_channels, output_channels, hidden_channels=32):\n",
    "        super(UNet_contracting, self).__init__()\n",
    "\n",
    "        self.upfeature = FeatureMap(input_channels, hidden_channels)\n",
    "        \n",
    "        self.contract1 = Contract(hidden_channels)\n",
    "        self.contract2 = Contract(hidden_channels * 2)\n",
    "        self.contract3 = Contract(hidden_channels * 4)\n",
    "        self.contract4 = Contract(hidden_channels * 8)\n",
    "        self.contract5 = Contract(hidden_channels * 16)\n",
    "\n",
    "    def forward(self, data_in):\n",
    "\n",
    "        contract_0 = self.upfeature(data_in)\n",
    "        \n",
    "        contract_1 = self.contract1(contract_0)\n",
    "        contract_2 = self.contract2(contract_1)\n",
    "        contract_3 = self.contract3(contract_2)\n",
    "        contract_4 = self.contract4(contract_3)\n",
    "        contract_5 = self.contract5(contract_4)\n",
    "\n",
    "        return contract_1,contract_2,contract_3,contract_4,contract_5\n",
    "\n",
    "#expanding path of the model\n",
    "class Expand(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(Expand, self).__init__()\n",
    "        \n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.conv1 = nn.Conv2d(input_channels, input_channels//2, kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(input_channels, input_channels//2, kernel_size=3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(input_channels//2, input_channels//2, kernel_size=3,padding=1)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, skip_con_x):\n",
    "        x = self.upsample(x)\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet\n",
    "        # /commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        diffY = skip_con_x.size()[2] - x.size()[2]\n",
    "        diffX = skip_con_x.size()[3] - x.size()[3]\n",
    "        x = F.pad(x, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
    "\n",
    "        x = torch.cat([skip_con_x, x], dim=1)\n",
    "        x = self.conv2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class UNet_expanding(nn.Module):\n",
    "\n",
    "    def __init__(self, contract_layers, output_channels, hidden_channels=32):\n",
    "        super(UNet_expanding, self).__init__()\n",
    "        \n",
    "        self.expand0 = Expand(hidden_channels * 32)\n",
    "        self.expand1 = Expand(hidden_channels * 16)\n",
    "        self.expand2 = Expand(hidden_channels * 8)\n",
    "        self.expand3 = Expand(hidden_channels * 4)\n",
    "        self.expand4 = Expand(hidden_channels * 2)\n",
    "        \n",
    "        self.downfeature = FeatureMap(hidden_channels, output_channels)\n",
    "        \n",
    "        # input image = 240, conv1 = 120, conv2 = 60, conv3 = 30 15 7 4\n",
    "        #self.Linear1 = nn.Linear(((hidden_channels * 32) * 7 * 7), output_channels) \n",
    "\n",
    "    def forward(self):\n",
    "\n",
    "        expand_1 = self.expand0(contract_5,contract_4)\n",
    "        expand_2 = self.expand1(expand_1,contract_3)\n",
    "        expand_3 = self.expand2(expand_2,contract_2)\n",
    "        expand_4 = self.expand3(expand_3,contract_1)\n",
    "        expand_5 = self.expand4(expand_4,contract_0)\n",
    "        \n",
    "        data_out = self.downfeature(expand_5)\n",
    "        \n",
    "        return data_out\n",
    "    \n",
    "class Full_UNet(nn.Module):\n",
    "    def __init__(self, contract, expand):\n",
    "        super(Full_UNet, self).__init__()\n",
    "        self.contract = contract\n",
    "        self.expand = expand\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.contract(x1)\n",
    "        x2 = self.expand(x2)\n",
    "        full_model = torch.cat((x1, x2), dim=1)\n",
    "        return full_model\n",
    "\n",
    "def Unet(input_dim, label_dim, hidden_dim, model_name):\n",
    "    # Create models and load state_dicts    \n",
    "    Contracting_path = UNet_contracting(input_dim, label_dim, hidden_dim)\n",
    "    Expanding_path = UNet_expanding(Contracting_path, label_dim, hidden_dim)\n",
    "\n",
    "    # Load state dicts\n",
    "    checkpoint = torch.load(model_name)\n",
    "    #checkpoint = torch.load(\"Checkpoints_RANO/Unet_8_2_data/checkpoint_49.pth\")\n",
    "\n",
    "    del checkpoint['state_dict'][\"Linear1.weight\"]\n",
    "    del checkpoint['state_dict'][\"Linear1.bias\"]\n",
    "\n",
    "    Contracting_path.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    #Freeze all layers in the pre-Trained model\n",
    "    for param in Contracting_path.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # concatenation of the contracting and expanding paths of the unet\n",
    "    model = Full_UNet(Contracting_path, Expanding_path)\n",
    "\n",
    "    #print(model)\n",
    "    return model\n",
    "\n",
    "input_dim = 4\n",
    "label_dim = 8\n",
    "hidden_dim = 32\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "model = Unet(input_dim, label_dim, hidden_dim,\"Checkpoints_RANO/Unet_8_2_data/checkpoint_49.pth\")\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
