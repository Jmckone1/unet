{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "export nnUNet_raw_data_base=\"/data/nnUNet_results/nnUNet_raw_data_base\"\n",
    "export nnUNet_preprocessed=\"/data/nnUNet_results/nnUNet_preprocessed\"\n",
    "export RESULTS_FOLDER=\"/data/nnUNet_results/nnUNet_trained_models\"\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=3 nnUNet_train 2d nnUNetTrainerV2Josh 6 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic packages for later use\n",
    "import os\n",
    "import shutil\n",
    "from collections import OrderedDict\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether GPU accelerated computing is available\n",
    "assert torch.cuda.is_available() # if there is an error here, enable GPU in the Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check if nnunet can be imported\n",
    "import nnunet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/wandb/run-20230201_121246-ljoogu2k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/joshmckone/nnU-Net_Workshop/runs/ljoogu2k\" target=\"_blank\">lunar-moon-1</a></strong> to <a href=\"https://wandb.ai/joshmckone/nnU-Net_Workshop\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/joshmckone/nnU-Net_Workshop\" target=\"_blank\">https://wandb.ai/joshmckone/nnU-Net_Workshop</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/joshmckone/nnU-Net_Workshop/runs/ljoogu2k\" target=\"_blank\">https://wandb.ai/joshmckone/nnU-Net_Workshop/runs/ljoogu2k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/joshmckone/nnU-Net_Workshop/runs/ljoogu2k?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f37a37d4630>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"nnU-Net_Workshop\")\n",
    "# ae32c1724511b998ba55b2fe6c8cdc16553ea2ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_if_dont_exist(folder_path,overwrite=False):\n",
    "    \"\"\"\n",
    "    creates a folder if it does not exists\n",
    "    input: \n",
    "    folder_path : relative path of the folder which needs to be created\n",
    "    over_write :(default: False) if True overwrite the existing folder \n",
    "    \"\"\"\n",
    "    if os.path.exists(folder_path):\n",
    "        \n",
    "        if not overwrite:\n",
    "            print(f\"{folder_path} exists.\")\n",
    "        else:\n",
    "            print(f\"{folder_path} overwritten\")\n",
    "            shutil.rmtree(folder_path)\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "    else:\n",
    "      os.makedirs(folder_path)\n",
    "      print(f\"{folder_path} created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory /data\n",
      "nnUNet_results/nnUNet_raw_data_base exists.\n",
      "nnUNet_results/nnUNet_preprocessed exists.\n",
      "nnUNet_results/nnUNet_Results_Folder created!\n",
      "nnUNet_results/RawData created!\n",
      "If No Error Occured Continue Forward. =)\n"
     ]
    }
   ],
   "source": [
    "# Maybe move path of preprocessed data directly on content - this may be signifcantely faster!\n",
    "print(\"Current Working Directory {}\".format(os.getcwd()))\n",
    "path_dict = {\n",
    "    \"nnUNet_raw_data_base\" : os.path.join(\"nnUNet_results\", \"nnUNet_raw_data_base\"), \n",
    "    \"nnUNet_preprocessed\" : os.path.join(\"nnUNet_results\", \"nnUNet_preprocessed\"), # 1 experiment: 1 epoch took 112s\n",
    "    # \"nnUNet_preprocessed\" : os.path.join(base_dir, \"nnUNet_preprocessed\"), # 1 experiment: 1 epoch took 108s -> seems faster take this\n",
    "    \"RESULTS_FOLDER\" : os.path.join(\"nnUNet_results\", \"nnUNet_Results_Folder\"),\n",
    "    \"RAW_DATA_PATH\" : os.path.join(\"nnUNet_results\", \"RawData\"), # This is used here only for convenience (not necessary for nnU-Net)!\n",
    "}\n",
    "\n",
    "# Write paths to environment variables\n",
    "for env_var, path in path_dict.items():\n",
    "  os.environ[env_var] = path \n",
    "\n",
    "# Check whether all environment variables are set correct!\n",
    "for env_var, path in path_dict.items():\n",
    "    if os.getenv(env_var) != path:\n",
    "        print(\"Error:\")\n",
    "        print(\"Environment Variable {} is not set correctly!\".format(env_var))\n",
    "        print(\"Should be {}\".format(path))\n",
    "        print(\"Variable is {}\".format(os.getenv(env_var)))\n",
    "    make_if_dont_exist(path, overwrite=False)\n",
    "\n",
    "print(\"If No Error Occured Continue Forward. =)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnUNet_results/nnUNet_raw_data_base/nnUNet_raw_data/Task006_Lung/imagesTr\n",
      "63 [{'image': './imagesTr/lung_047.nii.gz', 'label': './labelTr/lung_047.nii.gz'}, {'image': './imagesTr/lung_046.nii.gz', 'label': './labelTr/lung_046.nii.gz'}, {'image': './imagesTr/lung_070.nii.gz', 'label': './labelTr/lung_070.nii.gz'}, {'image': './imagesTr/lung_016.nii.gz', 'label': './labelTr/lung_016.nii.gz'}, {'image': './imagesTr/lung_061.nii.gz', 'label': './labelTr/lung_061.nii.gz'}, {'image': './imagesTr/lung_093.nii.gz', 'label': './labelTr/lung_093.nii.gz'}, {'image': './imagesTr/lung_086.nii.gz', 'label': './labelTr/lung_086.nii.gz'}, {'image': './imagesTr/lung_025.nii.gz', 'label': './labelTr/lung_025.nii.gz'}, {'image': './imagesTr/lung_065.nii.gz', 'label': './labelTr/lung_065.nii.gz'}, {'image': './imagesTr/lung_071.nii.gz', 'label': './labelTr/lung_071.nii.gz'}, {'image': './imagesTr/lung_041.nii.gz', 'label': './labelTr/lung_041.nii.gz'}, {'image': './imagesTr/lung_022.nii.gz', 'label': './labelTr/lung_022.nii.gz'}, {'image': './imagesTr/lung_033.nii.gz', 'label': './labelTr/lung_033.nii.gz'}, {'image': './imagesTr/lung_036.nii.gz', 'label': './labelTr/lung_036.nii.gz'}, {'image': './imagesTr/lung_018.nii.gz', 'label': './labelTr/lung_018.nii.gz'}, {'image': './imagesTr/lung_006.nii.gz', 'label': './labelTr/lung_006.nii.gz'}, {'image': './imagesTr/lung_092.nii.gz', 'label': './labelTr/lung_092.nii.gz'}, {'image': './imagesTr/lung_057.nii.gz', 'label': './labelTr/lung_057.nii.gz'}, {'image': './imagesTr/lung_037.nii.gz', 'label': './labelTr/lung_037.nii.gz'}, {'image': './imagesTr/lung_023.nii.gz', 'label': './labelTr/lung_023.nii.gz'}, {'image': './imagesTr/lung_080.nii.gz', 'label': './labelTr/lung_080.nii.gz'}, {'image': './imagesTr/lung_051.nii.gz', 'label': './labelTr/lung_051.nii.gz'}, {'image': './imagesTr/lung_079.nii.gz', 'label': './labelTr/lung_079.nii.gz'}, {'image': './imagesTr/lung_081.nii.gz', 'label': './labelTr/lung_081.nii.gz'}, {'image': './imagesTr/lung_054.nii.gz', 'label': './labelTr/lung_054.nii.gz'}, {'image': './imagesTr/lung_059.nii.gz', 'label': './labelTr/lung_059.nii.gz'}, {'image': './imagesTr/lung_075.nii.gz', 'label': './labelTr/lung_075.nii.gz'}, {'image': './imagesTr/lung_010.nii.gz', 'label': './labelTr/lung_010.nii.gz'}, {'image': './imagesTr/lung_038.nii.gz', 'label': './labelTr/lung_038.nii.gz'}, {'image': './imagesTr/lung_083.nii.gz', 'label': './labelTr/lung_083.nii.gz'}, {'image': './imagesTr/lung_028.nii.gz', 'label': './labelTr/lung_028.nii.gz'}, {'image': './imagesTr/lung_034.nii.gz', 'label': './labelTr/lung_034.nii.gz'}, {'image': './imagesTr/lung_042.nii.gz', 'label': './labelTr/lung_042.nii.gz'}, {'image': './imagesTr/lung_031.nii.gz', 'label': './labelTr/lung_031.nii.gz'}, {'image': './imagesTr/lung_020.nii.gz', 'label': './labelTr/lung_020.nii.gz'}, {'image': './imagesTr/lung_084.nii.gz', 'label': './labelTr/lung_084.nii.gz'}, {'image': './imagesTr/lung_073.nii.gz', 'label': './labelTr/lung_073.nii.gz'}, {'image': './imagesTr/lung_053.nii.gz', 'label': './labelTr/lung_053.nii.gz'}, {'image': './imagesTr/lung_015.nii.gz', 'label': './labelTr/lung_015.nii.gz'}, {'image': './imagesTr/lung_096.nii.gz', 'label': './labelTr/lung_096.nii.gz'}, {'image': './imagesTr/lung_055.nii.gz', 'label': './labelTr/lung_055.nii.gz'}, {'image': './imagesTr/lung_014.nii.gz', 'label': './labelTr/lung_014.nii.gz'}, {'image': './imagesTr/lung_005.nii.gz', 'label': './labelTr/lung_005.nii.gz'}, {'image': './imagesTr/lung_003.nii.gz', 'label': './labelTr/lung_003.nii.gz'}, {'image': './imagesTr/lung_095.nii.gz', 'label': './labelTr/lung_095.nii.gz'}, {'image': './imagesTr/lung_029.nii.gz', 'label': './labelTr/lung_029.nii.gz'}, {'image': './imagesTr/lung_066.nii.gz', 'label': './labelTr/lung_066.nii.gz'}, {'image': './imagesTr/lung_062.nii.gz', 'label': './labelTr/lung_062.nii.gz'}, {'image': './imagesTr/lung_044.nii.gz', 'label': './labelTr/lung_044.nii.gz'}, {'image': './imagesTr/lung_078.nii.gz', 'label': './labelTr/lung_078.nii.gz'}, {'image': './imagesTr/lung_004.nii.gz', 'label': './labelTr/lung_004.nii.gz'}, {'image': './imagesTr/lung_009.nii.gz', 'label': './labelTr/lung_009.nii.gz'}, {'image': './imagesTr/lung_058.nii.gz', 'label': './labelTr/lung_058.nii.gz'}, {'image': './imagesTr/lung_026.nii.gz', 'label': './labelTr/lung_026.nii.gz'}, {'image': './imagesTr/lung_043.nii.gz', 'label': './labelTr/lung_043.nii.gz'}, {'image': './imagesTr/lung_074.nii.gz', 'label': './labelTr/lung_074.nii.gz'}, {'image': './imagesTr/lung_064.nii.gz', 'label': './labelTr/lung_064.nii.gz'}, {'image': './imagesTr/lung_069.nii.gz', 'label': './labelTr/lung_069.nii.gz'}, {'image': './imagesTr/lung_045.nii.gz', 'label': './labelTr/lung_045.nii.gz'}, {'image': './imagesTr/lung_027.nii.gz', 'label': './labelTr/lung_027.nii.gz'}, {'image': './imagesTr/lung_048.nii.gz', 'label': './labelTr/lung_048.nii.gz'}, {'image': './imagesTr/lung_001.nii.gz', 'label': './labelTr/lung_001.nii.gz'}, {'image': './imagesTr/lung_049.nii.gz', 'label': './labelTr/lung_049.nii.gz'}]\n"
     ]
    }
   ],
   "source": [
    "from nnunet.dataset_conversion.utils import generate_dataset_json\n",
    "import os \n",
    "\n",
    "target_base = \"nnUNet_results/nnUNet_raw_data_base/nnUNet_raw_data/Task006_Lung\"\n",
    "target_imagesTr = target_base+ \"/imagesTr\"\n",
    "target_imagesTs = target_base+ \"/imagesTs\"\n",
    "target_labelsTs = target_base+ \"/labelsTs\"\n",
    "target_labelsTr = target_base+ \"/labelsTr\"\n",
    "\n",
    "# each extension - HGG or LGG\n",
    "counter = 0\n",
    "# each folder in extension\n",
    "print(target_imagesTr)\n",
    "path = target_imagesTr\n",
    "d = []\n",
    "for files in os.scandir(path):\n",
    "    if files.is_dir() or files.is_file():\n",
    "        if not files.name.startswith(\".\"):\n",
    "            d.append({\"image\":\"./imagesTr/\" + files.name,\"label\":\"./labelTr/\" + files.name})\n",
    "counter = len(d)\n",
    "print(counter,d)\n",
    "\n",
    "# #dictionary[\"training\"] = d\n",
    "\n",
    "# import json\n",
    "\n",
    "# jsonFile = open(target_base + '/dataset.json')\n",
    "# data = json.load(jsonFile)\n",
    "\n",
    "# #function to add to JSON\n",
    "# def write_json(new_data, filename=target_base + '/dataset.json'):\n",
    "#     with open(filename,'r+') as file:\n",
    "#           # First we load existing data into a dict.\n",
    "#         file_data = json.load(file)\n",
    "#         # Join new_data with file_data inside emp_details\n",
    "#         file_data[\"training\"].append(new_data)\n",
    "#         # Sets file's current position at offset.\n",
    "#         file.seek(0)\n",
    "#         # convert back to json.\n",
    "#         json.dump(file_data, file, indent = 4)\n",
    "\n",
    "# write_json(d)\n",
    "# # # finally we can call the utility for generating a dataset.json\n",
    "# # generate_dataset_json(target_base + \"/dataset.json\", target_imagesTr, target_imagesTs, \"0\",\n",
    "# #                           labels={0: 'background', 1: 'Tumour'}, dataset_name=\"Task06_Lung\", license='hands off!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnUNet_results/nnUNet_raw_data_base/nnUNet_raw_data/Task006_Lung/imagesTs\n",
      "lung_060_0000.nii.gz\n",
      "lung_076_0000.nii.gz\n",
      "lung_087_0000.nii.gz\n",
      "lung_039_0000.nii.gz\n",
      "lung_040_0000.nii.gz\n",
      "lung_068_0000.nii.gz\n",
      "lung_019_0000.nii.gz\n",
      "lung_024_0000.nii.gz\n",
      "lung_050_0000.nii.gz\n",
      "lung_011_0000.nii.gz\n",
      "lung_032_0000.nii.gz\n",
      "lung_013_0000.nii.gz\n",
      "lung_035_0000.nii.gz\n",
      "lung_089_0000.nii.gz\n",
      "lung_067_0000.nii.gz\n",
      "lung_090_0000.nii.gz\n",
      "lung_063_0000.nii.gz\n",
      "lung_052_0000.nii.gz\n",
      "lung_007_0000.nii.gz\n",
      "lung_082_0000.nii.gz\n",
      "lung_012_0000.nii.gz\n",
      "lung_030_0000.nii.gz\n",
      "lung_002_0000.nii.gz\n",
      "lung_017_0000.nii.gz\n",
      "lung_077_0000.nii.gz\n",
      "lung_021_0000.nii.gz\n",
      "lung_008_0000.nii.gz\n",
      "lung_091_0000.nii.gz\n",
      "lung_085_0000.nii.gz\n",
      "lung_072_0000.nii.gz\n",
      "lung_088_0000.nii.gz\n",
      "lung_056_0000.nii.gz\n",
      "0 []\n"
     ]
    }
   ],
   "source": [
    "from nnunet.dataset_conversion.utils import generate_dataset_json\n",
    "import os \n",
    "\n",
    "target_base = \"nnUNet_results/nnUNet_raw_data_base/nnUNet_raw_data/Task006_Lung\"\n",
    "target_imagesTr = target_base+ \"/imagesTr\"\n",
    "target_imagesTs = target_base+ \"/imagesTs\"\n",
    "target_labelsTs = target_base+ \"/labelsTs\"\n",
    "target_labelsTr = target_base+ \"/labelsTr\"\n",
    "\n",
    "# each extension - HGG or LGG\n",
    "counter = 0\n",
    "# each folder in extension\n",
    "print(target_imagesTs)\n",
    "path = target_imagesTs\n",
    "\n",
    "d = []\n",
    "for files in os.scandir(path):\n",
    "    if files.is_dir() or files.is_file():\n",
    "        if not files.name.startswith(\".\"):\n",
    "            if files.name[8:] != \"_0000.nii.gz\":\n",
    "                rename = files.name[:-7] + \"_0000.nii.gz\"\n",
    "                os.rename(path + \"/\" + files.name, path + \"/\" + files.name[:-7] + \"_0000.nii.gz\")\n",
    "            print(rename)\n",
    "            \n",
    "            #d.append({\"image\":\"./imagesTr/\" + files.name,\"label\":\"./labelTr/\" + files.name})\n",
    "counter = len(d)\n",
    "print(counter,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "nnUNet_raw_data_base is not defined and nnU-Net can only be used on data for which preprocessed files are already present on your system. nnU-Net cannot be used for experiment planning and preprocessing like this. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up properly.\n",
      "nnUNet_preprocessed is not defined and nnU-Net can not be used for preprocessing or training. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up.\n",
      "RESULTS_FOLDER is not defined and nnU-Net cannot be used for training or inference. If this is not intended behavior, please read documentation/setting_up_paths.md for information on how to set this up.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/nnUNet_plan_and_preprocess\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('nnunet', 'console_scripts', 'nnUNet_plan_and_preprocess')())\n",
      "  File \"/data/nnUNet/nnunet/experiment_planning/nnUNet_plan_and_preprocess.py\", line 102, in main\n",
      "    task_name = convert_id_to_task_name(i)\n",
      "  File \"/data/nnUNet/nnunet/utilities/task_name_id_conversion.py\", line 59, in convert_id_to_task_name\n",
      "    os.environ.get('nnUNet_raw_data_base') if os.environ.get('nnUNet_raw_data_base') is not None else 'None',\n",
      "RuntimeError: Could not find a task with the ID 6. Make sure the requested task ID exists and that nnU-Net knows where raw and preprocessed data are located (see Documentation - Installation). Here are your currently defined folders:\n",
      "nnUNet_preprocessed=None\n",
      "RESULTS_FOLDER=None\n",
      "nnUNet_raw_data_base=None\n",
      "If something is not right, adapt your environemnt variables.\n"
     ]
    }
   ],
   "source": [
    "# Prepare the Execution of nnU-Net for Task 4 - this is the Hippocampus Dataset here (taking 1-2 minutes)\n",
    "!nnUNet_plan_and_preprocess -t 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network can only be one of the following: \n",
    "# '2d', \n",
    "# '3d_lowres', \n",
    "# '3d_fullres', \n",
    "# '3d_cascade_fullres'\n",
    "\n",
    "\n",
    "# nnUNet_train 2d nnUNet_encoder_trainer_josh 6 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 240)\n",
      "(512, 512, 240)\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "def dataread(path):\n",
    "    d = []\n",
    "    \n",
    "    for (dir_path, dir_names, file_names) in walk(path):\n",
    "        #print(file_names)\n",
    "        # gets rid of any pesky leftover .ipynb_checkpoints files\n",
    "        if not file_names == []:\n",
    "            for name in range(len(file_names)):\n",
    "                if not file_names[name].startswith(\".\"):\n",
    "                    d.append(file_names[name])\n",
    "    return d\n",
    "\n",
    "path1 = \"nnUNet_results/nnUNet_preprocessed/Task006_Lung/gt_segmentations_/lung_041.nii.gz\" \n",
    "path2 = \"nnUNet_results/nnUNet_preprocessed/Task006_Lung/gt_segmentations/lung_041.nii.gz\"\n",
    "\n",
    "data_Plot = nib.load(path1)\n",
    "input_2 = data_Plot.get_fdata()\n",
    "\n",
    "print(input_2.shape)\n",
    "\n",
    "data_Plot = nib.load(path2)\n",
    "input_2 = data_Plot.get_fdata()\n",
    "\n",
    "print(input_2.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
